#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Parquet í˜•ì‹ìœ¼ë¡œ ì €ì¥ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì˜ˆì œ ì½”ë“œ
ì‘ì„±ì: Review Data Analyzer
ì‘ì„±ì¼: 2025-01-27
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
import matplotlib.font_manager as fm
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False


import sys
import os
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ config ëª¨ë“ˆì„ ì„í¬íŠ¸í•  ìˆ˜ ìˆë„ë¡ í•¨
sys.path.append(str(Path(__file__).resolve().parent.parent))

from config import PARQUET_DATA_DIR

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows)
import matplotlib.font_manager as fm
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False


class ReviewAnalyzer:
    """Parquet í˜•ì‹ì˜ ë¦¬ë·° ë°ì´í„° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: str = PARQUET_DATA_DIR):
        """
        ì´ˆê¸°í™”
        
        Args:
            data_dir: Parquet íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        """
        self.data_dir = Path(data_dir)
        self.df_restaurants = None
        self.df_reviews = None
        
    def load_data(self):
        """Parquet íŒŒì¼ ë¡œë“œ"""
        print("ğŸ“‚ Parquet íŒŒì¼ ë¡œë”© ì¤‘...")
        
        restaurants_path = self.data_dir / 'restaurants.parquet'
        reviews_path = self.data_dir / 'reviews.parquet'
        
        self.df_restaurants = pd.read_parquet(restaurants_path)
        self.df_reviews = pd.read_parquet(reviews_path)
        
        print(f"âœ… ë ˆìŠ¤í† ë‘ {len(self.df_restaurants):,}ê°œ ë¡œë“œ ì™„ë£Œ")
        print(f"âœ… ë¦¬ë·° {len(self.df_reviews):,}ê°œ ë¡œë“œ ì™„ë£Œ")
        
    def basic_statistics(self):
        """ê¸°ë³¸ í†µê³„ ë¶„ì„"""
        print("\nğŸ“Š ê¸°ë³¸ í†µê³„ ë¶„ì„")
        print("="*60)
        
        # 1. Gridë³„ ë ˆìŠ¤í† ë‘ ìˆ˜
        print("\n1. Gridë³„ ë ˆìŠ¤í† ë‘ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
        grid_counts = self.df_restaurants['grid'].value_counts().head(10)
        for grid, count in grid_counts.items():
            print(f"   {grid}: {count}ê°œ")
        
        # 2. ì–¸ì–´ë³„ ë¦¬ë·° ë¶„í¬
        print("\n2. ì–¸ì–´ë³„ ë¦¬ë·° ë¶„í¬:")
        lang_counts = self.df_reviews['language'].value_counts()
        for lang, count in lang_counts.head(10).items():
            pct = count / len(self.df_reviews) * 100
            print(f"   {lang}: {count:,}ê°œ ({pct:.1f}%)")
        
        # 3. í‰ì  í†µê³„
        print("\n3. í‰ì  í†µê³„:")
        print(f"   í‰ê·  í‰ì : {self.df_reviews['rating'].mean():.2f}")
        print(f"   ì¤‘ì•™ê°’: {self.df_reviews['rating'].median():.1f}")
        print(f"   í‘œì¤€í¸ì°¨: {self.df_reviews['rating'].std():.2f}")
        
        # 4. ë¦¬ë·° ê¸¸ì´ í†µê³„
        print("\n4. ë¦¬ë·° ê¸¸ì´ í†µê³„:")
        print(f"   í‰ê·  ê¸¸ì´: {self.df_reviews['text_length'].mean():.0f}ì")
        print(f"   ìµœì†Œ ê¸¸ì´: {self.df_reviews['text_length'].min()}ì")
        print(f"   ìµœëŒ€ ê¸¸ì´: {self.df_reviews['text_length'].max()}ì")
        print(f"   ì¤‘ì•™ê°’: {self.df_reviews['text_length'].median():.0f}ì")
        
    def analyze_top_restaurants(self, n=20):
        """ìƒìœ„ ë ˆìŠ¤í† ë‘ ë¶„ì„"""
        print(f"\nğŸ† ìƒìœ„ {n}ê°œ ë ˆìŠ¤í† ë‘ (ë¦¬ë·° ìˆ˜ ê¸°ì¤€)")
        print("="*60)
        
        top_restaurants = self.df_restaurants.nlargest(n, 'reviews_count')
        
        for idx, row in top_restaurants.iterrows():
            # í•´ë‹¹ ë ˆìŠ¤í† ë‘ì˜ ë¦¬ë·°ë“¤ ê°€ì ¸ì˜¤ê¸°
            restaurant_reviews = self.df_reviews[
                self.df_reviews['restaurant_id'] == row['restaurant_id']
            ]
            
            # ì–¸ì–´ ë¶„í¬
            lang_dist = restaurant_reviews['language'].value_counts().head(3)
            lang_str = ", ".join([f"{lang}({cnt})" for lang, cnt in lang_dist.items()])
            
            print(f"\n{row['name']} ({row['grid']})")
            print(f"  ğŸ“ í‰ì : {row['rating']:.1f} | ë¦¬ë·°: {row['reviews_count']}ê°œ")
            print(f"  ğŸ“ ì–¸ì–´: {lang_str}")
            print(f"  ğŸ“Š ë¦¬ë·° í‰ì  ë¶„í¬: ", end="")
            for rating in [1, 2, 3, 4, 5]:
                count = (restaurant_reviews['rating'] == rating).sum()
                print(f"{rating}â˜…({count}) ", end="")
        
    def analyze_by_grid(self):
        """Gridë³„ ë¶„ì„"""
        print("\nğŸ—ºï¸ Gridë³„ ìƒì„¸ ë¶„ì„")
        print("="*60)
        
        # Gridë³„ í†µê³„ ê³„ì‚°
        grid_stats = []
        for grid in self.df_restaurants['grid'].unique():
            grid_restaurants = self.df_restaurants[self.df_restaurants['grid'] == grid]
            grid_reviews = self.df_reviews[self.df_reviews['grid'] == grid]
            
            stats = {
                'grid': grid,
                'restaurant_count': len(grid_restaurants),
                'review_count': len(grid_reviews),
                'avg_rating': grid_restaurants['rating'].mean(),
                'avg_review_per_restaurant': len(grid_reviews) / max(len(grid_restaurants), 1),
                'korean_review_pct': (grid_reviews['language'] == 'ko').mean() * 100
            }
            grid_stats.append(stats)
        
        df_grid_stats = pd.DataFrame(grid_stats)
        df_grid_stats = df_grid_stats.sort_values('review_count', ascending=False)
        
        print("\nGridë³„ í†µê³„ (ë¦¬ë·° ìˆ˜ ìƒìœ„ 10ê°œ):")
        for _, row in df_grid_stats.head(10).iterrows():
            print(f"\n{row['grid']}:")
            print(f"  ë ˆìŠ¤í† ë‘: {row['restaurant_count']}ê°œ")
            print(f"  ë¦¬ë·°: {row['review_count']}ê°œ")
            print(f"  í‰ê·  í‰ì : {row['avg_rating']:.2f}")
            print(f"  ë ˆìŠ¤í† ë‘ë‹¹ í‰ê·  ë¦¬ë·°: {row['avg_review_per_restaurant']:.1f}ê°œ")
            print(f"  í•œêµ­ì–´ ë¦¬ë·° ë¹„ìœ¨: {row['korean_review_pct']:.1f}%")
        
        return df_grid_stats
    
    def analyze_korean_reviews(self):
        """í•œêµ­ì–´ ë¦¬ë·° íŠ¹ë³„ ë¶„ì„"""
        print("\nğŸ‡°ğŸ‡· í•œêµ­ì–´ ë¦¬ë·° ë¶„ì„")
        print("="*60)
        
        korean_reviews = self.df_reviews[self.df_reviews['language'] == 'ko']
        print(f"ì´ í•œêµ­ì–´ ë¦¬ë·° ìˆ˜: {len(korean_reviews):,}ê°œ")
        print(f"ì „ì²´ ë¦¬ë·° ì¤‘ ë¹„ìœ¨: {len(korean_reviews)/len(self.df_reviews)*100:.1f}%")
        
        # í•œêµ­ì–´ ë¦¬ë·°ê°€ ë§ì€ ë ˆìŠ¤í† ë‘
        korean_review_counts = korean_reviews.groupby('restaurant_name').size()
        top_korean = korean_review_counts.nlargest(10)
        
        print("\ní•œêµ­ì–´ ë¦¬ë·°ê°€ ë§ì€ ë ˆìŠ¤í† ë‘ TOP 10:")
        for name, count in top_korean.items():
            restaurant_info = self.df_restaurants[
                self.df_restaurants['name'] == name
            ].iloc[0] if len(self.df_restaurants[self.df_restaurants['name'] == name]) > 0 else None
            
            if restaurant_info is not None:
                total_reviews = restaurant_info['reviews_count']
                korean_pct = (count / total_reviews * 100) if total_reviews > 0 else 0
                print(f"  â€¢ {name}: {count}ê°œ ({korean_pct:.1f}% í•œêµ­ì–´)")
        
        # í•œêµ­ì–´ ë¦¬ë·° í‰ì  vs ì „ì²´ í‰ì 
        print(f"\ní‰ì  ë¹„êµ:")
        print(f"  í•œêµ­ì–´ ë¦¬ë·° í‰ê·  í‰ì : {korean_reviews['rating'].mean():.2f}")
        print(f"  ì „ì²´ ë¦¬ë·° í‰ê·  í‰ì : {self.df_reviews['rating'].mean():.2f}")
        
    def search_restaurants(self, keyword: str):
        """ë ˆìŠ¤í† ë‘ ê²€ìƒ‰ ê¸°ëŠ¥"""
        print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼")
        print("="*60)
        
        # ë ˆìŠ¤í† ë‘ ì´ë¦„ì—ì„œ ê²€ìƒ‰
        matches = self.df_restaurants[
            self.df_restaurants['name'].str.contains(keyword, case=False, na=False)
        ]
        
        if len(matches) == 0:
            print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ì´ {len(matches)}ê°œ ë ˆìŠ¤í† ë‘ ë°œê²¬:")
        for _, restaurant in matches.head(10).iterrows():
            print(f"\nâ€¢ {restaurant['name']} ({restaurant['grid']})")
            print(f"  í‰ì : {restaurant['rating']:.1f} | ë¦¬ë·°: {restaurant['reviews_count']}ê°œ")
            print(f"  ì£¼ì†Œ: {restaurant['address'][:50]}...")
            
            # í•´ë‹¹ ë ˆìŠ¤í† ë‘ì˜ ìƒ˜í”Œ ë¦¬ë·°
            sample_reviews = self.df_reviews[
                self.df_reviews['restaurant_id'] == restaurant['restaurant_id']
            ].head(2)
            
            if len(sample_reviews) > 0:
                print("  ìƒ˜í”Œ ë¦¬ë·°:")
                for _, review in sample_reviews.iterrows():
                    text = review['text'][:100] if len(review['text']) > 100 else review['text']
                    print(f"    - [{review['rating']}â˜…] {text}...")
    
    def export_filtered_data(self, condition: str, output_name: str):
        """ì¡°ê±´ì— ë§ëŠ” ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥"""
        print(f"\nğŸ’¾ ì¡°ê±´ë¶€ ë°ì´í„° ì¶”ì¶œ: {condition}")
        
        # ì˜ˆì‹œ: í‰ì  4.5 ì´ìƒ ë ˆìŠ¤í† ë‘ì˜ ë¦¬ë·°ë§Œ ì¶”ì¶œ
        if condition == "high_rating":
            high_rated = self.df_restaurants[self.df_restaurants['rating'] >= 4.5]
            restaurant_ids = high_rated['restaurant_id'].tolist()
            filtered_reviews = self.df_reviews[
                self.df_reviews['restaurant_id'].isin(restaurant_ids)
            ]
            
            output_path = self.data_dir / f"{output_name}.parquet"
            filtered_reviews.to_parquet(output_path, compression='snappy')
            print(f"âœ… {len(filtered_reviews):,}ê°œ ë¦¬ë·°ë¥¼ {output_path}ì— ì €ì¥")
            
        # ì¶”ê°€ ì¡°ê±´ë“¤ì„ ì—¬ê¸°ì— êµ¬í˜„ ê°€ëŠ¥


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\nğŸ” NYC Restaurant Reviews Parquet Data Analyzer")
    print("="*60)
    
    analyzer = ReviewAnalyzer()
    
    # ë°ì´í„° ë¡œë“œ
    analyzer.load_data()
    
    # ê¸°ë³¸ í†µê³„
    analyzer.basic_statistics()
    
    # ìƒìœ„ ë ˆìŠ¤í† ë‘ ë¶„ì„
    analyzer.analyze_top_restaurants(n=10)
    
    # Gridë³„ ë¶„ì„
    grid_stats = analyzer.analyze_by_grid()
    
    # í•œêµ­ì–´ ë¦¬ë·° ë¶„ì„
    analyzer.analyze_korean_reviews()
    
    # ê²€ìƒ‰ ì˜ˆì‹œ
    print("\n" + "="*60)
    analyzer.search_restaurants("Pizza")
    
    # ë°ì´í„° ì¶”ì¶œ ì˜ˆì‹œ
    # analyzer.export_filtered_data("high_rating", "high_rated_reviews")
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
    
    # ê°„ë‹¨í•œ ì¿¼ë¦¬ ì˜ˆì‹œ
    reviews_parquet_path = PARQUET_DATA_DIR / 'reviews.parquet'
    print("\nğŸ“ Parquet ë°ì´í„° ì¿¼ë¦¬ ì˜ˆì‹œ:")
    print("="*60)
    print(f"""
# Parquet íŒŒì¼ì„ ì§ì ‘ ì¿¼ë¦¬í•˜ëŠ” ë°©ë²•:

import pandas as pd
import pyarrow.parquet as pq

# 1. ì „ì²´ ë°ì´í„° ë¡œë“œ
df = pd.read_parquet('{reviews_parquet_path}')

# 2. íŠ¹ì • ì»¬ëŸ¼ë§Œ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
df = pd.read_parquet('{reviews_parquet_path}', 
                    columns=['restaurant_name', 'rating', 'text'])

# 3. ì¡°ê±´ë¶€ í•„í„°ë§ (PyArrow ì‚¬ìš©)
import pyarrow.parquet as pq
import pyarrow.compute as pc

table = pq.read_table('{reviews_parquet_path}')
# í‰ì  5ì ì¸ ë¦¬ë·°ë§Œ
high_rated = table.filter(pc.equal(table['rating'], 5))
df = high_rated.to_pandas()

# 4. SQL ìŠ¤íƒ€ì¼ ì¿¼ë¦¬ (DuckDB ì‚¬ìš©)
import duckdb
conn = duckdb.connect()
result = conn.execute('''
    SELECT restaurant_name, AVG(rating) as avg_rating, COUNT(*) as review_count
    FROM '{reviews_parquet_path}'
    WHERE language = 'ko'
    GROUP BY restaurant_name
    ORDER BY review_count DESC
    LIMIT 10
''').fetchdf()
    """)


if __name__ == "__main__":
    main()


if __name__ == "__main__":
    main()
