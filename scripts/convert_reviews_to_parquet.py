#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ë¦¬ë·° JSON íŒŒì¼ì„ Parquet í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì: Review Data Converter
ì‘ì„±ì¼: 2025-01-27
"""

import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import re
from typing import Dict, List, Tuple
import logging
import warnings
warnings.filterwarnings('ignore')

import sys
from typing import Dict, List, Tuple
import logging
import warnings

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ config ëª¨ë“ˆì„ ì„í¬íŠ¸í•  ìˆ˜ ìˆë„ë¡ í•¨
sys.path.append(str(Path(__file__).resolve().parent.parent))

from config import REVIEWS_DIR, PARQUET_DATA_DIR, LOG_DIR

warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
log_file_path = LOG_DIR / 'conversion.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file_path, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ReviewsToParquetConverter:
    """ë¦¬ë·° JSON íŒŒì¼ì„ Parquetìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, reviews_dir: str = REVIEWS_DIR,
                 output_dir: str = PARQUET_DATA_DIR):
        """
        ì´ˆê¸°í™”
        
        Args:
            reviews_dir: ë¦¬ë·° JSON íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
            output_dir: Parquet íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬
        """
        self.reviews_dir = Path(reviews_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.restaurants_data = []
        self.reviews_data = []
        self.error_files = []
        
    def parse_date(self, date_str: str) -> Tuple[datetime, bool]:
        """
        í•œêµ­ì–´/ì˜ì–´ ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±
        
        Args:
            date_str: ë‚ ì§œ ë¬¸ìì—´ (ì˜ˆ: "2ì£¼ ì „", "1ë‹¬ ì „", "ìˆ˜ì •ì¼: 3ë‹¬ ì „")
            
        Returns:
            (ì¶”ì • ë‚ ì§œ, ìˆ˜ì • ì—¬ë¶€)
        """
        try:
            # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€
            base_date = datetime.now()
            is_modified = False
            
            # ìˆ˜ì •ì¼ ì²´í¬
            if "ìˆ˜ì •ì¼:" in date_str or "ìˆ˜ì •ì¼:" in date_str:
                is_modified = True
                date_str = date_str.replace("ìˆ˜ì •ì¼:", "").replace("ìˆ˜ì •ì¼:", "").strip()
            
            # ìƒëŒ€ ì‹œê°„ íŒŒì‹±
            if "ì „" in date_str:
                # ìˆ«ì ì¶”ì¶œ
                numbers = re.findall(r'\d+', date_str)
                if numbers:
                    num = int(numbers[0])
                else:
                    num = 1
                
                if "ì¼" in date_str or "day" in date_str.lower():
                    days_ago = num
                elif "ì£¼" in date_str or "week" in date_str.lower():
                    days_ago = num * 7
                elif "ë‹¬" in date_str or "month" in date_str.lower():
                    days_ago = num * 30
                elif "ë…„" in date_str or "year" in date_str.lower():
                    days_ago = num * 365
                else:
                    days_ago = 0
                    
                estimated_date = pd.Timestamp(base_date) - pd.Timedelta(days=days_ago)
            else:
                # ê¸°ë³¸ê°’: í˜„ì¬ ë‚ ì§œ
                estimated_date = pd.Timestamp(base_date)
                
            return estimated_date, is_modified
            
        except Exception as e:
            logger.warning(f"ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str} - {str(e)}")
            return pd.Timestamp(base_date), False
    
    def process_json_file(self, file_path: Path) -> bool:
        """
        ë‹¨ì¼ JSON íŒŒì¼ ì²˜ë¦¬
        
        Args:
            file_path: JSON íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ë ˆìŠ¤í† ë‘ ì •ë³´ ì¶”ì¶œ
            restaurant_info = {
                'restaurant_id': data.get('place_id', ''),
                'name': data.get('name', ''),
                'grid': data.get('grid', ''),
                'address': data.get('address', ''),
                'rating': float(data.get('rating', 0)),
                'user_ratings_total': int(data.get('user_ratings_total', 0)),
                'phone_number': data.get('phone_number', ''),
                'reviews_count': int(data.get('reviews_count', 0)),
                'file_path': str(file_path)
            }
            self.restaurants_data.append(restaurant_info)
            
            # ë¦¬ë·° ì •ë³´ ì¶”ì¶œ
            reviews = data.get('reviews', [])
            for review in reviews:
                # ë‚ ì§œ íŒŒì‹±
                estimated_date, is_modified = self.parse_date(review.get('date', ''))
                
                review_info = {
                    'review_id': review.get('review_id', ''),
                    'restaurant_id': data.get('place_id', ''),
                    'restaurant_name': data.get('name', ''),
                    'grid': data.get('grid', ''),
                    'date_original': review.get('date', ''),
                    'estimated_date': estimated_date,
                    'is_modified': is_modified,
                    'language': review.get('language', ''),
                    'rating': float(review.get('rating', 0)),
                    'text': review.get('text', ''),
                    'text_length': len(review.get('text', '')),
                }
                self.reviews_data.append(review_info)
            
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path} - {str(e)}")
            self.error_files.append(str(file_path))
            return False
    
    def convert_all_files(self):
        """ëª¨ë“  JSON íŒŒì¼ì„ ë³€í™˜"""
        logger.info("JSON íŒŒì¼ ê²€ìƒ‰ ì‹œì‘...")
        
        # ëª¨ë“  JSON íŒŒì¼ ì°¾ê¸°
        json_files = list(self.reviews_dir.glob("**/*_reviews.json"))
        total_files = len(json_files)
        
        logger.info(f"ì´ {total_files}ê°œì˜ JSON íŒŒì¼ ë°œê²¬")
        
        # ê° íŒŒì¼ ì²˜ë¦¬
        for i, file_path in enumerate(json_files, 1):
            if i % 100 == 0:
                logger.info(f"ì§„í–‰ ìƒí™©: {i}/{total_files} íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
            self.process_json_file(file_path)
        
        logger.info(f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {total_files - len(self.error_files)}ê°œ, ì‹¤íŒ¨ {len(self.error_files)}ê°œ")
    
    def create_parquet_files(self):
        """Parquet íŒŒì¼ ìƒì„±"""
        if not self.restaurants_data or not self.reviews_data:
            logger.error("ë³€í™˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë ˆìŠ¤í† ë‘ DataFrame ìƒì„±
        logger.info("ë ˆìŠ¤í† ë‘ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘...")
        df_restaurants = pd.DataFrame(self.restaurants_data)
        
        # ë°ì´í„° íƒ€ì… ìµœì í™”
        df_restaurants['grid'] = df_restaurants['grid'].astype('category')
        
        # ë¦¬ë·° DataFrame ìƒì„±
        logger.info("ë¦¬ë·° ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘...")
        df_reviews = pd.DataFrame(self.reviews_data)
        
        # ë°ì´í„° íƒ€ì… ìµœì í™”
        df_reviews['grid'] = df_reviews['grid'].astype('category')
        df_reviews['language'] = df_reviews['language'].astype('category')
        df_reviews['rating'] = df_reviews['rating'].astype('int8')
        
        # Parquet íŒŒì¼ ì €ì¥
        restaurants_path = self.output_dir / 'restaurants.parquet'
        reviews_path = self.output_dir / 'reviews.parquet'
        
        logger.info("Parquet íŒŒì¼ ì €ì¥ ì¤‘...")
        df_restaurants.to_parquet(
            restaurants_path,
            engine='pyarrow',
            compression='snappy',
            index=False
        )
        
        df_reviews.to_parquet(
            reviews_path,
            engine='pyarrow',
            compression='snappy',
            index=False
        )
        
        # í†µê³„ ì¶œë ¥
        self.print_statistics(df_restaurants, df_reviews)
        
        # ìƒ˜í”Œ ë°ì´í„° ì €ì¥ (ë¶„ì„ í™•ì¸ìš©)
        self.save_samples(df_restaurants, df_reviews)
        
        logger.info(f"ë³€í™˜ ì™„ë£Œ! íŒŒì¼ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
        
    def print_statistics(self, df_restaurants: pd.DataFrame, df_reviews: pd.DataFrame):
        """ë°ì´í„° í†µê³„ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š ë°ì´í„° ë³€í™˜ ê²°ê³¼ í†µê³„")
        print("="*60)
        
        print(f"\nğŸ“ ë ˆìŠ¤í† ë‘ ë°ì´í„°:")
        print(f"  - ì´ ë ˆìŠ¤í† ë‘ ìˆ˜: {len(df_restaurants):,}ê°œ")
        print(f"  - Grid ë¶„í¬:")
        for grid, count in df_restaurants['grid'].value_counts().head(10).items():
            print(f"    â€¢ {grid}: {count}ê°œ")
        print(f"  - í‰ê·  í‰ì : {df_restaurants['rating'].mean():.2f}")
        print(f"  - í‰ê·  ë¦¬ë·° ìˆ˜: {df_restaurants['reviews_count'].mean():.1f}ê°œ")
        
        print(f"\nğŸ’¬ ë¦¬ë·° ë°ì´í„°:")
        print(f"  - ì´ ë¦¬ë·° ìˆ˜: {len(df_reviews):,}ê°œ")
        print(f"  - ì–¸ì–´ ë¶„í¬:")
        for lang, count in df_reviews['language'].value_counts().head(5).items():
            pct = count / len(df_reviews) * 100
            print(f"    â€¢ {lang}: {count:,}ê°œ ({pct:.1f}%)")
        print(f"  - í‰ê·  ë¦¬ë·° ê¸¸ì´: {df_reviews['text_length'].mean():.0f}ì")
        print(f"  - í‰ì  ë¶„í¬:")
        for rating in sorted(df_reviews['rating'].unique()):
            count = (df_reviews['rating'] == rating).sum()
            pct = count / len(df_reviews) * 100
            print(f"    â€¢ {rating}ì : {count:,}ê°œ ({pct:.1f}%)")
        
        # íŒŒì¼ í¬ê¸° ì •ë³´
        restaurants_size = (self.output_dir / 'restaurants.parquet').stat().st_size / (1024*1024)
        reviews_size = (self.output_dir / 'reviews.parquet').stat().st_size / (1024*1024)
        
        print(f"\nğŸ’¾ íŒŒì¼ í¬ê¸°:")
        print(f"  - restaurants.parquet: {restaurants_size:.2f} MB")
        print(f"  - reviews.parquet: {reviews_size:.2f} MB")
        print("="*60)
        
    def save_samples(self, df_restaurants: pd.DataFrame, df_reviews: pd.DataFrame):
        """ìƒ˜í”Œ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥ (í™•ì¸ìš©)"""
        # ë ˆìŠ¤í† ë‘ ìƒ˜í”Œ
        sample_restaurants = df_restaurants.head(100)
        sample_restaurants.to_csv(
            self.output_dir / 'sample_restaurants.csv',
            index=False,
            encoding='utf-8-sig'
        )
        
        # ë¦¬ë·° ìƒ˜í”Œ
        sample_reviews = df_reviews.head(100)
        sample_reviews.to_csv(
            self.output_dir / 'sample_reviews.csv',
            index=False,
            encoding='utf-8-sig'
        )
        
        logger.info("ìƒ˜í”Œ CSV íŒŒì¼ ìƒì„± ì™„ë£Œ")
    
    def run(self):
        """ì „ì²´ ë³€í™˜ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info("ë¦¬ë·° ë°ì´í„° Parquet ë³€í™˜ ì‹œì‘")
        
        # JSON íŒŒì¼ ì²˜ë¦¬
        self.convert_all_files()
        
        # Parquet íŒŒì¼ ìƒì„±
        self.create_parquet_files()
        
        # ì—ëŸ¬ íŒŒì¼ ë¡œê¹…
        if self.error_files:
            logger.warning(f"ì²˜ë¦¬ ì‹¤íŒ¨ íŒŒì¼ ëª©ë¡:")
            for file in self.error_files:
                logger.warning(f"  - {file}")
        
        logger.info("ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\nğŸš€ NYC Restaurant Reviews JSON to Parquet Converter")
    print("="*60)
    
    try:
        # í•„ìš”í•œ íŒ¨í‚¤ì§€ ì²´í¬
        try:
            import pyarrow
        except ImportError:
            print("âš ï¸ pyarrowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...")
            os.system("pip install pyarrow")
            import pyarrow
        
        # ë³€í™˜ê¸° ì‹¤í–‰
        converter = ReviewsToParquetConverter()
        converter.run()
        
        print("\nâœ… ë³€í™˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {PARQUET_DATA_DIR}")
        print("\në‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print("  â€¢ restaurants.parquet - ë ˆìŠ¤í† ë‘ ì •ë³´")
        print("  â€¢ reviews.parquet - ëª¨ë“  ë¦¬ë·° ë°ì´í„°")
        print("  â€¢ sample_restaurants.csv - ë ˆìŠ¤í† ë‘ ìƒ˜í”Œ (í™•ì¸ìš©)")
        print("  â€¢ sample_reviews.csv - ë¦¬ë·° ìƒ˜í”Œ (í™•ì¸ìš©)")
        print(f"  â€¢ {log_file_path.name} - ë³€í™˜ ë¡œê·¸")
        
    except Exception as e:
        logger.error(f"ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"ìì„¸í•œ ë‚´ìš©ì€ {log_file_path} íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()


if __name__ == "__main__":
    main()
